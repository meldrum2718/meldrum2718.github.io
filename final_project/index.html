<!DOCTYPE html> <html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Final Project</title>

  <style>
    body {
      background-color: #2a2a32;
      color: #b0b0b0; /* Softer grey for text */
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    a {
      color: #8bbdd9;
    }
    code {
      background-color: #3a3a44;
      color: #d1d1d1;
      padding: 2px 4px;
      border-radius: 4px;
    }
    pre {
      background-color: #3a3a44;
      color: #d1d1d1;
      padding: 10px;
      border-radius: 5px;
      overflow-x: auto;
    }
    blockquote {
      background-color: #3a3a44;
      color: #d1d1d1;
      padding: 1em;
      border-left: 5px solid #8bbdd9;
      border-radius: 4px;
    }
    h1, h2, h3 {
      color: #4f709c;
      font-family: 'Helvetica Neue', Arial, sans-serif;
    }
		.image-container {
      text-align: center;
      margin: 10px 0;
    }
	img {
		max-width: 80%;    /* Limits the maximum width of images */
		height: auto;      /* Maintains aspect ratio */
		margin: 10px; /* Adds margin of 10px on top and bottom, and centers the image horizontally */
		display: inline-block;     /* Ensures that the margin auto will work for centering */
	}
	.replay-on-hover {
		display: block;
		margin: 20px auto; /* Center the video */
		max-width: 90%;    /* Limit the video size */
		border-radius: 8px; /* Rounded corners for the video */
	}
  </style>
</head>
<body>

    <header>
        <h1>Final Project: Neural Radiance Fields </h1>
    </header>

    <section>

        <div class="project">

            <p> In this project we implement Neural Radiance Fields, a technique for parameterizing a radiance field with a neural network.

            <br>


            <p>

            <hr>
            <h3> Part 1: The 2d Case </h3>

            We first look at the 2d case. We train a simple Multilayer
            Perceptron (MLP) to learn the RGB pixel values from a 2d coordinate
            (i, j) in the unit square [0, 1]^2, structured as shown below:

            <br>
            <div class="image-container">
              <img src="images/mlp_arch.png" alt="Image", style="width: 55%">
            </div>
            <br>



            We use a sinusoidal positional encoding (PE) at the start of the
            network to project the input 2 dimensional coordinate (x, y) into
            2*(2*L + 1) dimensional space, with the coordinates of the higher
            dimensional representation given by [x, y, sin(2^0 pi x), cos(2^0
            pi x), sin(2^0 pi y), sin(22^1 pi x), sin(2^1 pi x), cos(2^1 pi x),
            sin(2^1 pi y), sin(2^1 pi x), ...]. This enables the network to see
            high frequency (high precision) information about the coordinates.
            Without this positional encoding, the network does not learn fine
            grained spatial structure accurately, as we shall see below.


            <br>
            <br>

            Once the MLP has been trained on an image, we can use it to
            reconstruct the image by making predictions on a mesh over the unit
            square. Thus we are training the MLP to parameterize a function
            from the unit square to the unit cube. It is interesting to note
            that this is precisely the task that we used bilinear image
            interpolation for in previous projects such as face warping and
            image stitching, only now with a more flexible parameterization.
            <br>
            <br>

            <br>
            <br>


            This is the target image that we use for this section.
            <br>
            <div class="image-container">
              <img src="images/fox.jpg" alt="Image", style="width: 55%">
            </div>
            <br>

            This is a reconstruction by a neural network:
            <br>
            <div class="image-container">
              <img src="images/fox_pred.png" alt="Image", style="width: 55%">
            </div>
            <br>



            Now we look at some examples of the image that the network learns.
            Each of the below plots shows the networks predictions at different
            stages of the training process.
            <br>

            We additionally show the training loss curves, as well as the peak
            signal to noise ratio (PSNR), computed as 10*log(1/mse). Where mse is the mean squared error training loss.

            <br>
            <br>

            We fix 256 hidden channels, 2 layers, training for 1000 steps
            with batch size of 10,000. We vary the positional encoding
            dimension, indexed by L.
            <br>
            <br>
            With L=10:
            <br>
            <div class="image-container">
              <img src="images/preds_L10_dh_256_nl2_ns1000_bs10000.png" alt="Image", style="width: 100%">
              <img src="images/loss_L10_dh_256_nl2_ns1000_bs10000.png" alt="Image", style="width: 55%">
            </div>
            <br>


            <br>
            <br>
            With L=3:
            <br>
            <div class="image-container">
              <img src="images/preds_L3_dh_256_nl2_ns1000_bs10000.png" alt="Image", style="width: 100%">
              <img src="images/loss_L3_dh_256_nl2_ns1000_bs10000.png" alt="Image", style="width: 55%">
            </div>
            <br>

            <br>
            <br>
            With L=0:
            <br>
            <div class="image-container">
              <img src="images/preds_L3_dh_256_nl2_ns1000_bs10000.png" alt="Image", style="width: 100%">
              <img src="images/loss_L3_dh_256_nl2_ns1000_bs10000.png" alt="Image", style="width: 55%">
            </div>
            <br>

            This demonstrates that the positional encoding is indeed helping the network to work with higher spatial frequencies.

            <br>
            <br>
            <br>

            Now we fix L=10, and vary the number of hidden channels.

            <br>
            <br>
            With 256 hidden channels:
            <br>
            <div class="image-container">
              <img src="images/preds_L10_dh_256_nl2_ns1000_bs10000.png" alt="Image", style="width: 100%">
              <img src="images/loss_L10_dh_256_nl2_ns1000_bs10000.png" alt="Image", style="width: 55%">
            </div>
            <br>


            <br>
            <br>
            With 64 hidden channels:
            <br>
            <div class="image-container">
              <img src="images/preds_L10_dh_64_nl2_ns1000_bs10000.png" alt="Image", style="width: 100%">
              <img src="images/loss_L10_dh_64_nl2_ns1000_bs10000.png" alt="Image", style="width: 55%">
            </div>
            <br>

            <br>
            <br>
            With 16 hidden channels:
            <br>
            <div class="image-container">
              <img src="images/preds_L10_dh_16_nl2_ns1000_bs10000.png" alt="Image", style="width: 100%">
              <img src="images/loss_L10_dh_16_nl2_ns1000_bs10000.png" alt="Image", style="width: 55%">
            </div>
            <br>


            <br>
            <br>
            With 8 hidden channels:
            <br>
            <div class="image-container">
              <img src="images/preds_L10_dh_8_nl2_ns1000_bs10000.png" alt="Image", style="width: 100%">
              <img src="images/loss_L10_dh_8_nl2_ns1000_bs10000.png" alt="Image", style="width: 55%">
            </div>
            <br>

            <br>
            <br>
            With 4 hidden channels:
            <br>
            <div class="image-container">
              <img src="images/preds_L10_dh_4_nl2_ns1000_bs10000.png" alt="Image", style="width: 100%">
              <img src="images/loss_L10_dh_4_nl2_ns1000_bs10000.png" alt="Image", style="width: 55%">
            </div>
            <br>

            <br>
            <br>
            With 2 hidden channels:
            <br>
            <div class="image-container">
              <img src="images/preds_L10_dh_2_nl2_ns1000_bs10000.png" alt="Image", style="width: 100%">
              <img src="images/loss_L10_dh_2_nl2_ns1000_bs10000.png" alt="Image", style="width: 55%">
            </div>
            <br>


            Here we can see that as the number of hidden channels goes to one, the representational power of the network is greatly reduced.


            <hr>

            <br>
            <br>
            Below we see the training process on another image
            <br>
            <div class="image-container">
              <img src="images/preds_nebula.png" alt="Image", style="width: 100%">
              <img src="images/loss_nebula.png" alt="Image", style="width: 55%">
            </div>
            <br>


            <br>
            <br>

            <hr>
            <h3> Part 2: The full 3d Situation </h3>
            Now we use a neural radiance field to represent a 3 dimensional
            scene. We start with many images of the same scene taken from
            different angles. We need to know the specific location and camera
            direction for each image. With this information we can create a map
            from pixels in the training data to rays in the real 3d space.

            <br>
            <br>

            To create such a map, we first use the inverse of the intrinsic
            matrix to map from pixel space to camera coordinates, and then we
            use the extrinsic matrix (which contains the information about the
            location and orientation of the camera) to map from camera
            coordinates to world coordinates.

            <br>
            <br>

            Now we can compute a ray associated with a pixel by looking at the
            subspace spanned by the camera location and the pixel location in
            world coordinates.

            <br>
            <br>

            We additionally set up a random sampler that produces a random selection of rays from our dataset.

            <br>
            <div class="image-container">
              <img src="images/some_sample_rays.png" alt="Image", style="width: 55%">
              <img src="images/single_camera_rays.png" alt="Image", style="width: 55%">
            </div>
            <br>





        </div>

    </section>

    <footer>
    </footer>



    <script>
        // Function to add replay-on-hover behavior
        function enableReplayOnHover(className) {
            const videos = document.querySelectorAll(`.${className}`);
            videos.forEach(video => {
                video.addEventListener('ended', () => {
                    video.pause(); // Pause at the end
                });
                video.addEventListener('mouseover', () => {
                    video.currentTime = 0; // Reset to the start
                    video.play();          // Play the video
                });
            });
        }

        // Apply the behavior to all videos with the specified class
        enableReplayOnHover('replay-on-hover');
    </script>



</body>
</html>
